{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data to panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read relevant columns to panda dataframe\n",
    "\n",
    "# please use your own path for this\n",
    "path = \"./\"\n",
    "admission = pd.read_csv(path + 'ADMISSIONS.csv', usecols=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', \n",
    "                                                   'DEATHTIME', 'ADMISSION_TYPE', 'DISCHARGE_LOCATION', 'DIAGNOSIS'])\n",
    "# convert admission time and discharge time death time to correct format\n",
    "admission.ADMITTIME = pd.to_datetime(admission.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "admission.DISCHTIME = pd.to_datetime(admission.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "admission.DEATHTIME = pd.to_datetime(admission.DEATHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort before group by\n",
    "admission = admission.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "admission = admission.reset_index(drop = True)\n",
    "\n",
    "# add the next admission date and type for each subject \n",
    "admission['NEXT_ADMITTIME'] = admission.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
    "admission['NEXT_ADMISSION_TYPE'] = admission.groupby('SUBJECT_ID').ADMISSION_TYPE.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admission = admission.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "# back fill\n",
    "admission[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']] = admission.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']].fillna(method = 'bfill')\n",
    "# compute days elapsed until next readmission\n",
    "admission['DAYS_NEXT_ADMIT']=  (admission.NEXT_ADMITTIME - admission.DISCHTIME).dt.total_seconds()/(24*60*60)\n",
    "# number of records that were readmitted in less than or equal to 30 days: 3390\n",
    "records = admission[admission.DAYS_NEXT_ADMIT <= 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaor/CSE258/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read the notes table \n",
    "notes = pd.read_csv(path + \"NOTEEVENTS.csv\")\n",
    "discharge_sum = notes.loc[notes.CATEGORY == 'Discharge summary']\n",
    "notes_dis_sum_last = (discharge_sum.groupby(['SUBJECT_ID','HADM_ID']).nth(-1)).reset_index()\n",
    "\n",
    "# perform a left join of the two datatable\n",
    "dt_table = pd.merge(admission,notes_dis_sum_last[['SUBJECT_ID','HADM_ID','TEXT']], on = ['SUBJECT_ID','HADM_ID'],how = 'left')\n",
    "# filter out new born records because a lot of them don't have discharge summary\n",
    "dt_table = dt_table[dt_table.ADMISSION_TYPE != 'NEWBORN']\n",
    "# filter out records that do not have discharge summary\n",
    "\n",
    "# add a column for label\n",
    "dt_table['LABEL'] = (dt_table.DAYS_NEXT_ADMIT <= 30).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a column for predicting readmission type:\n",
    "# A three-class classification problem [No Readmission, Emergency, Elective] = [0, 1, 2]\n",
    "labelDict = defaultdict(int)\n",
    "def label_readmission_type(row):\n",
    "    if row['NEXT_ADMISSION_TYPE'] == 'EMERGENCY':\n",
    "        labelDict['class 1'] = labelDict['class 1'] + 1\n",
    "        return 1\n",
    "    elif row['NEXT_ADMISSION_TYPE'] == 'ELECTIVE':\n",
    "        labelDict['class 2'] = labelDict['class 2'] + 1\n",
    "        return 2\n",
    "    else:\n",
    "        labelDict['class 0'] = labelDict['class 0'] + 1\n",
    "        return 0\n",
    "dt_table['LABELTYPE'] = dt_table.apply(lambda row: label_readmission_type(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a smaller test set \n",
    "# shuffle the dataset first:\n",
    "dt_table_shuffled = dt_table.sample(n=len(dt_table), random_state=42)\n",
    "dt_table_shuffled = dt_table_shuffled.reset_index(drop=True)\n",
    "dt_train = dt_table_shuffled.sample(frac=0.80, random_state=42)\n",
    "dt_val_test = dt_table_shuffled.drop(dt_train.index)\n",
    "dt_val = dt_val_test.sample(frac=0.50, random_state=42)\n",
    "dt_test = dt_val_test.drop(dt_val.index)\n",
    "\n",
    "# sub-sampling negative data:\n",
    "posRow = dt_train.LABEL==1\n",
    "dt_train_pos = dt_train.loc[posRow]\n",
    "dt_train_neg = dt_train.loc[~posRow]\n",
    "dt_train_sub = pd.concat([dt_train_pos, dt_train_neg.sample(n=len(dt_train_pos), random_state=42)], axis=0)\n",
    "# re-shuffle sub-sampled training dataset:\n",
    "dt_train_sub = dt_train_sub.sample(n=len(dt_train_sub), random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5111, 15)\n",
      "(5111, 15)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing:\n",
    "# Fill missing notes with space and remove CRLF\n",
    "# Tokenize free-text\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "def my_tokenizer(text):\n",
    "    # remove +'0123456789'\n",
    "    punc_list = string.punctuation\n",
    "    tranTable = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.lower().translate(tranTable)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def preprocess_text(df):\n",
    "    # This function preprocesses the text by filling not a number and replacing new lines ('\\n') and carriage returns ('\\r')\n",
    "    df.TEXT = df.TEXT.fillna(' ')\n",
    "    return df\n",
    "\n",
    "print(dt_test.shape)\n",
    "dt_train_sub = preprocess_text(dt_train_sub)\n",
    "dt_val = preprocess_text(dt_val)\n",
    "dt_test = preprocess_text(dt_test)\n",
    "print (dt_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 15)\n"
     ]
    }
   ],
   "source": [
    "dt_demo = dt_test[:200]\n",
    "print (dt_demo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert tokens into word vectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "rawCountVec = CountVectorizer(max_features=3000, tokenizer=my_tokenizer, ngram_range=(1, 3), stop_words=stop_words)\n",
    "tfidfVec = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), tokenizer=my_tokenizer, min_df=3, max_df=0.9, \n",
    "                           strip_accents='unicode', use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=stop_words)\n",
    "rawX_train = rawCountVec.fit_transform(dt_train_sub.TEXT.values)\n",
    "rawX_val = rawCountVec.transform(dt_val.TEXT.values)\n",
    "rawX_test = rawCountVec.transform(dt_test.TEXT.values)\n",
    "tfidftX_train = tfidfVec.fit_transform(dt_train_sub.TEXT.values)\n",
    "tfidfX_val = tfidfVec.transform(dt_val.TEXT.values)\n",
    "tfidfX_test = tfidfVec.transform(dt_test.TEXT.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5076, 3000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidftX_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Readmission Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load models \n",
    "# Model 1: SVM with BoW\n",
    "with open('svm_model.pickle', 'rb') as handle:\n",
    "    svm_bow = pickle.load(handle)\n",
    "# Model 2: SVM with TFIDF\n",
    "with open('svm_model_tfidf.pickle', 'rb') as handle:\n",
    "    svm_tfidf= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracting TFIDF Features\n",
    "tf_feat = TfidfVectorizer(max_features=380249,ngram_range=(1, 3), tokenizer=my_tokenizer, min_df=3, max_df=0.9, \n",
    "                           strip_accents='unicode', use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words=stop_words)\n",
    "tf_train = tf_feat.fit_transform(dt_train_sub.TEXT.values)\n",
    "tf_valid = tf_feat.transform(dt_val.TEXT.values)\n",
    "tf_test = tf_feat.transform(dt_test.TEXT.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5111, 380249)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM using BOW Feature 0.335\n",
      "Macro F1 for SVM using BOW Feature 0.2847731978166761\n",
      "Micro F1 for SVM using BOW Feature 0.335\n",
      "Accuracy for SVM using TFIDF Feature 0.94\n",
      "Macro F1 for SVM using TFIDF Feature 0.4845360824742268\n",
      "Micro F1 for SVM using TFIDF Feature 0.94\n"
     ]
    }
   ],
   "source": [
    "# get some metrics for the first 200 samples \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# sample demo \n",
    "# get label \n",
    "y_demo = dt_demo.LABEL.values\n",
    "# get feature \n",
    "x_demo_bow = rawX_test[:200]\n",
    "x_demo_tfidf = tf_test[:200]\n",
    "# prediction \n",
    "y_pred = svm_bow.predict(x_demo_bow)\n",
    "svm_bow_accuracy = accuracy_score(y_demo, y_pred)\n",
    "macroF1 = f1_score(y_demo, y_pred, average='macro')\n",
    "microF1 = f1_score(y_demo, y_pred, average='micro')\n",
    "print (\"Accuracy for SVM using BOW Feature\", svm_bow_accuracy)\n",
    "print (\"Macro F1 for SVM using BOW Feature\", macroF1)\n",
    "print (\"Micro F1 for SVM using BOW Feature\", microF1)\n",
    "y_pred = svm_tfidf.predict(x_demo_tfidf)\n",
    "svm_tfidf_accuracy = accuracy_score(y_demo, y_pred)\n",
    "print (\"Accuracy for SVM using TFIDF Feature\", svm_tfidf_accuracy)\n",
    "macroF1 = f1_score(y_demo, y_pred, average='macro')\n",
    "microF1 = f1_score(y_demo, y_pred, average='micro')\n",
    "print (\"Macro F1 for SVM using TFIDF Feature\", macroF1)\n",
    "print (\"Micro F1 for SVM using TFIDF Feature\", microF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting readmission type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # train a baseline Logistic Regression:\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# model = LogisticRegression(C=0.0002, class_weight='balanced', solver='lbfgs', penalty='l2', random_state=0, tol=1e-6)\n",
    "# # using raw count vecotrs\n",
    "# model.fit(rawX_train, y_trainMul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded!!\n"
     ]
    }
   ],
   "source": [
    "# load from pickle file:\n",
    "with open(\"LogisticRegression_Multiclass.pkl\", \"rb\") as handle:\n",
    "    lr_multi = pickle.load(handle)\n",
    "print(\"Pickle loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression using BOW Feature 0.64\n",
      "Macro F1 score: 0.338005, Micro F1 score: 0.640000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# sample demo \n",
    "# get label \n",
    "y_demo = dt_demo.LABELTYPE.values\n",
    "# get feature \n",
    "x_demo_bow = rawX_test[:200]\n",
    "#x_demo_tfidf = tfidfX_test[:20]\n",
    "# prediction \n",
    "y_pred = lr_multi.predict(x_demo_bow)\n",
    "lr_multi_accuracy = accuracy_score(y_demo, y_pred)\n",
    "print (\"Accuracy for Logistic Regression using BOW Feature\", lr_multi_accuracy)\n",
    "#y_pred = svm_tfidf.predict(x_demo_tfidf)\n",
    "macroF1 = f1_score(y_demo, y_pred, average='macro')\n",
    "microF1 = f1_score(y_demo, y_pred, average='micro')\n",
    "print(\"Macro F1 score: %02f, Micro F1 score: %02f\" % (macroF1, microF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2104, 1: 2785, 2: 187}\n"
     ]
    }
   ],
   "source": [
    "# Get labels for multiclass classification for validation dataset\n",
    "# multiclass (3) classification:\n",
    "y_trainMul = dt_train_sub.LABELTYPE.values\n",
    "y_valMul = dt_val.LABELTYPE.values\n",
    "unique, counts = np.unique(y_trainMul, return_counts=True)\n",
    "uniqueLabelsDict = dict(zip(unique, counts))\n",
    "print(uniqueLabelsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse258",
   "language": "python",
   "name": "cse258"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
