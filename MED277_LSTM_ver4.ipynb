{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Classification Problem\n",
    "#### convert text into word vectors\n",
    "#### train LSTM\n",
    "#### have a dense layer (activation is softmax) at the end\n",
    "#### the output from the dense layer is a number, and we can think of it as a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation and add a column for label:\n",
    "path = \"../\"\n",
    "admission = pd.read_csv(path + 'ADMISSIONS.csv', usecols=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', \n",
    "                                                   'DEATHTIME', 'ADMISSION_TYPE', 'DISCHARGE_LOCATION', 'DIAGNOSIS'])\n",
    "# convert admission time and discharge time death time to correct format\n",
    "admission.ADMITTIME = pd.to_datetime(admission.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "admission.DISCHTIME = pd.to_datetime(admission.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "admission.DEATHTIME = pd.to_datetime(admission.DEATHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "# sort before group by\n",
    "admission = admission.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "admission = admission.reset_index(drop = True)\n",
    "\n",
    "# add the next admission date and type for each subject \n",
    "admission['NEXT_ADMITTIME'] = admission.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
    "admission['NEXT_ADMISSION_TYPE'] = admission.groupby('SUBJECT_ID').ADMISSION_TYPE.shift(-1)\n",
    "admission = admission.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "# back fill\n",
    "admission[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']] = admission.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']].fillna(method = 'bfill')\n",
    "# compute days elapsed until next readmission\n",
    "admission['DAYS_NEXT_ADMIT']=  (admission.NEXT_ADMITTIME - admission.DISCHTIME).dt.total_seconds()/(24*60*60)\n",
    "# number of records that were readmitted in less than or equal to 30 days: 3390\n",
    "records = admission[admission.DAYS_NEXT_ADMIT <= 30]\n",
    "# read the notes table \n",
    "notes = pd.read_csv(path + \"NOTEEVENTS.csv\")\n",
    "discharge_sum = notes.loc[notes.CATEGORY == 'Discharge summary']\n",
    "notes_dis_sum_last = (discharge_sum.groupby(['SUBJECT_ID','HADM_ID']).nth(-1)).reset_index()\n",
    "# perform a left join of the two datatable\n",
    "dt_table = pd.merge(admission,notes_dis_sum_last[['SUBJECT_ID','HADM_ID','TEXT']], on = ['SUBJECT_ID','HADM_ID'],how = 'left')\n",
    "# filter out new born records because a lot of them don't have discharge summary\n",
    "dt_table = dt_table[dt_table.ADMISSION_TYPE != 'NEWBORN']\n",
    "# add a column for label\n",
    "dt_table['LABEL'] = (dt_table.DAYS_NEXT_ADMIT <= 30).astype('int')\n",
    "# split the dataset into 80% training, 10% validation, and 10% testing:\n",
    "# shuffle the dataset first:\n",
    "dt_table_shuffled = dt_table.sample(n=len(dt_table), random_state=42)\n",
    "dt_table_shuffled = dt_table_shuffled.reset_index(drop=True)\n",
    "dt_train = dt_table_shuffled.sample(frac=0.80, random_state=42)\n",
    "dt_val_test = dt_table_shuffled.drop(dt_train.index)\n",
    "dt_val = dt_val_test.sample(frac=0.50, random_state=42)\n",
    "dt_test = dt_val_test.drop(dt_val.index)\n",
    "# skip sub-sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>NEXT_ADMISSION_TYPE</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25985</td>\n",
       "      <td>21284</td>\n",
       "      <td>126923</td>\n",
       "      <td>2168-05-03 07:15:00</td>\n",
       "      <td>2168-05-10 14:50:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>ASCENDING AORTIC  ANEURSYM\\ ASCENDING AROTA W/...</td>\n",
       "      <td>2171-02-04 04:04:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>999.551389</td>\n",
       "      <td>Admission Date: [**2168-5-3**]        Discharg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11435</td>\n",
       "      <td>9344</td>\n",
       "      <td>116730</td>\n",
       "      <td>2199-05-21 02:59:00</td>\n",
       "      <td>2199-06-26 14:32:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>REHAB/DISTINCT PART HOSP</td>\n",
       "      <td>GUN SHOT WOUND</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2199-5-21**]              ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
       "0   25985       21284   126923 2168-05-03 07:15:00 2168-05-10 14:50:00   \n",
       "1   11435        9344   116730 2199-05-21 02:59:00 2199-06-26 14:32:00   \n",
       "\n",
       "  DEATHTIME ADMISSION_TYPE        DISCHARGE_LOCATION  \\\n",
       "0       NaT       ELECTIVE          HOME HEALTH CARE   \n",
       "1       NaT      EMERGENCY  REHAB/DISTINCT PART HOSP   \n",
       "\n",
       "                                           DIAGNOSIS      NEXT_ADMITTIME  \\\n",
       "0  ASCENDING AORTIC  ANEURSYM\\ ASCENDING AROTA W/... 2171-02-04 04:04:00   \n",
       "1                                     GUN SHOT WOUND                 NaT   \n",
       "\n",
       "  NEXT_ADMISSION_TYPE  DAYS_NEXT_ADMIT  \\\n",
       "0           EMERGENCY       999.551389   \n",
       "1                 NaN              NaN   \n",
       "\n",
       "                                                TEXT  LABEL  \n",
       "0  Admission Date: [**2168-5-3**]        Discharg...      0  \n",
       "1  Admission Date:  [**2199-5-21**]              ...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_table_shuffled[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "import string\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    notes = text.strip().split()\n",
    "    for words in notes:\n",
    "        r = ''.join([c for c in words.lower() if not c in punctuation])\n",
    "        if (r not in gensim.parsing.preprocessing.STOPWORDS):\n",
    "            result.append(r)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 409 4796\n",
      "ADMISSION DIAGNOSIS:\n",
      "1. Aneurysm of ascending aorta and aortic arch.\n",
      "2. Hypertension.\n",
      "3. Hypercholesterolemia.\n",
      "4. Diabetes mellitus, type 2.\n",
      "5. Hypothyroidism.\n",
      "6. Glaucoma.\n",
      "7. Osteoarthritis.\n",
      "8. Status post total abdominal hysterectomy.\n",
      "9. Status post colonic polypectomy.\n",
      "\n",
      "\n",
      "DISCHARGE DIAGNOSIS:\n",
      "1. Aneurysm of ascending aorta and aortic arch, status post\n",
      "   replacement of ascending aorta and hemi-arch and aortic\n",
      "   valve resuspension with 32 mm gel-weave tube graft.\n",
      "2. Hypertension.\n",
      "3. Hypercholesterolemia.\n",
      "4. Diabetes mellitus, type 2.\n",
      "5. Hypothyroidism.\n",
      "6. Glaucoma.\n",
      "7. Osteoarthritis.\n",
      "8. Status post total abdominal hysterectomy.\n",
      "9. Status post colonic polypectomy.\n",
      "\n",
      "\n",
      "HISTORY OF PRESENT ILLNESS:  The patient is a 71-year-old\n",
      "female who was found to have mildly dilated abdominal aortic\n",
      "aneurysm on work-up for a heart murmur she had been diagnosed\n",
      "with. This had been followed serially with echocardiogram and\n",
      "was found to have grown to 5.5 cm in [**2168-2-23**]. As noted,\n",
      "she had otherwise been asymptomatic, but given the growing\n",
      "size of the aneurysm and its overall size, she was scheduled\n",
      "for elective repair of this.\n",
      "\n",
      "PHYSICAL EXAMINATION:  Vital signs: The patient was afebrile\n",
      "and hemodynamically normal. Pulse 58, blood pressure 150\n",
      "systolic/70 in the right arm and 140 systolic/80 in the left\n",
      "arm. She was saturating 98% on room air. Her preoperative\n",
      "weight was 174 lb. Heart: Exam was notable for a 3/6 systolic\n",
      "ejection murmur but was otherwise essentially unremarkable.\n",
      "\n",
      "PREOPERATIVE LABS:  Hematocrit 35.9; BUN and creatinine of 16\n",
      "and 0.7.\n",
      "\n",
      "HOSPITAL COURSE:  The patient was admitted to the hospital on\n",
      "[**2168-5-3**], and on that same day, she underwent\n",
      "replacement of her ascending aorta and hemi-arch and aortic\n",
      "valve resuspension with a 32 mm gel-weave tube graft.\n",
      "Cardiopulmonary bypass time was 117 minutes. Cross-clamp time\n",
      "was 69 minutes. She had 15 minutes of circulatory arrest.\n",
      "\n",
      "The patient was taken intubated from the operating room to\n",
      "the cardiac surgery intensive care unit where she was\n",
      "maintained on vasopressor for blood pressure support, and she\n",
      "remained mechanically ventilated.\n",
      "\n",
      "She was extubated mid day, on postoperative day #1, and\n",
      "subsequently developed respiratory acidosis, which was felt\n",
      "to be secondary to a combination of pain medication and\n",
      "respiratory fatigue. She was subsequently placed on BIPAP\n",
      "ventilation over night, which she tolerated well, which\n",
      "allowed for resolution of her respiratory acidosis without\n",
      "use of further invasive ventilation.\n",
      "\n",
      "By postoperative day #2, the patient was doing well and was\n",
      "otherwise off vasopressors. She was transferred to the\n",
      "general floor on postoperative day #3 where she continued to\n",
      "do well with her main issue essentially being pulmonary\n",
      "toilet for low oxygen saturation.\n",
      "\n",
      "Her chest tubes were removed on postoperative day #4, and she\n",
      "continued to work with physical therapy who felt that she\n",
      "would be a safe candidate for discharge to home with home\n",
      "physical therapy.\n",
      "\n",
      "Throughout the course of her hospitalization, we maintained\n",
      "strict glucose control with use of her home Metformin, and\n",
      "regular insulin sliding scale was needed. Diuresis was\n",
      "started on postoperative day #1 as per routine with good\n",
      "result. The patient was 3 kg above her preoperative weight at\n",
      "the time of discharge.\n",
      "\n",
      "It was felt that by postoperative day #7, as the patient had\n",
      "been afebrile, she had otherwise been hemodynamically normal,\n",
      "with a pulse in the 70-80s and a systolic pressure in the\n",
      "120s, with an oxygen saturation of 100% on 2 L, and otherwise\n",
      "unremarkable physical examination with only trace edema in\n",
      "the extremities and a clean wound, that the patient could be\n",
      "safely discharged to home with home physical therapy and home\n",
      "oxygenation.\n",
      "\n",
      "At the time of discharge, her hematocrit was 30, and her BUN\n",
      "and creatinine were 19 and 0.6.\n",
      "\n",
      "FO[**Last Name (STitle) 996**]P:  She was discharged to home with follow-up with\n",
      "her primary care physician, [**Last Name (NamePattern4) **]. [**Last Name (STitle) **] and Dr. [**Last Name (Prefixes) **]\n",
      "in four weeks.\n",
      "\n",
      "DISCHARGE MEDICATIONS:  Lopressor 25 mg p.o. b.i.d., Colace\n",
      "100 mg p.o. b.i.d. as needed, Zantac 150 mg p.o. b.i.d. as\n",
      "needed, aspirin 81 mg p.o. once daily, Ibuprofen 400 mg p.o.\n",
      "q.8 hours as needed, Dorzolamide-Timolol 2-0.5% eye drops 1\n",
      "drop b.i.d., pilocarpine 1% drops 1 drop q.8 hours,\n",
      "Latanoprost 0.005% drops 1 drop at bed time, Metformin 500 mg\n",
      "p.o. once daily, Synthroid 50 mcg p.o. once daily, Lasix 20\n",
      "mg p.o. b.i.d. for 5 days, potassium chloride 20 mEq p.o.\n",
      "b.i.d. for 4-5 days.\n",
      "\n",
      "DISPOSITION:  The patient will be discharged to home with\n",
      "home physical therapy and on home oxygen.\n",
      "['admission', 'diagnosis', '1', 'aneurysm', 'ascending', 'aorta', 'aortic', 'arch', '2', 'hypertension', '3', 'hypercholesterolemia', '4', 'diabetes', 'mellitus', 'type', '2', '5', 'hypothyroidism', '6', 'glaucoma', '7', 'osteoarthritis', '8', 'status', 'post', 'total', 'abdominal', 'hysterectomy', '9', 'status', 'post', 'colonic', 'polypectomy', 'discharge', 'diagnosis', '1', 'aneurysm', 'ascending', 'aorta', 'aortic', 'arch', 'status', 'post', 'replacement', 'ascending', 'aorta', 'hemiarch', 'aortic', 'valve', 'resuspension', '32', 'mm', 'gelweave', 'tube', 'graft', '2', 'hypertension', '3', 'hypercholesterolemia', '4', 'diabetes', 'mellitus', 'type', '2', '5', 'hypothyroidism', '6', 'glaucoma', '7', 'osteoarthritis', '8', 'status', 'post', 'total', 'abdominal', 'hysterectomy', '9', 'status', 'post', 'colonic', 'polypectomy', 'history', 'present', 'illness', 'patient', '71yearold', 'female', 'mildly', 'dilated', 'abdominal', 'aortic', 'aneurysm', 'workup', 'heart', 'murmur', 'diagnosed', 'followed', 'serially', 'echocardiogram', 'grown', '55', 'cm', '2168223', 'noted', 'asymptomatic', 'given', 'growing', 'size', 'aneurysm', 'overall', 'size', 'scheduled', 'elective', 'repair', 'physical', 'examination', 'vital', 'signs', 'patient', 'afebrile', 'hemodynamically', 'normal', 'pulse', '58', 'blood', 'pressure', '150', 'systolic70', 'right', 'arm', '140', 'systolic80', 'left', 'arm', 'saturating', '98', 'room', 'air', 'preoperative', 'weight', '174', 'lb', 'heart', 'exam', 'notable', '36', 'systolic', 'ejection', 'murmur', 'essentially', 'unremarkable', 'preoperative', 'labs', 'hematocrit', '359', 'bun', 'creatinine', '16', '07', 'hospital', 'course', 'patient', 'admitted', 'hospital', '216853', 'day', 'underwent', 'replacement', 'ascending', 'aorta', 'hemiarch', 'aortic', 'valve', 'resuspension', '32', 'mm', 'gelweave', 'tube', 'graft', 'cardiopulmonary', 'bypass', 'time', '117', 'minutes', 'crossclamp', 'time', '69', 'minutes', '15', 'minutes', 'circulatory', 'arrest', 'patient', 'taken', 'intubated', 'operating', 'room', 'cardiac', 'surgery', 'intensive', 'care', 'unit', 'maintained', 'vasopressor', 'blood', 'pressure', 'support', 'remained', 'mechanically', 'ventilated', 'extubated', 'mid', 'day', 'postoperative', 'day', '1', 'subsequently', 'developed', 'respiratory', 'acidosis', 'felt', 'secondary', 'combination', 'pain', 'medication', 'respiratory', 'fatigue', 'subsequently', 'placed', 'bipap', 'ventilation', 'night', 'tolerated', 'allowed', 'resolution', 'respiratory', 'acidosis', 'use', 'invasive', 'ventilation', 'postoperative', 'day', '2', 'patient', 'vasopressors', 'transferred', 'general', 'floor', 'postoperative', 'day', '3', 'continued', 'main', 'issue', 'essentially', 'pulmonary', 'toilet', 'low', 'oxygen', 'saturation', 'chest', 'tubes', 'removed', 'postoperative', 'day', '4', 'continued', 'work', 'physical', 'therapy', 'felt', 'safe', 'candidate', 'discharge', 'home', 'home', 'physical', 'therapy', 'course', 'hospitalization', 'maintained', 'strict', 'glucose', 'control', 'use', 'home', 'metformin', 'regular', 'insulin', 'sliding', 'scale', 'needed', 'diuresis', 'started', 'postoperative', 'day', '1', 'routine', 'good', 'result', 'patient', '3', 'preoperative', 'weight', 'time', 'discharge', 'felt', 'postoperative', 'day', '7', 'patient', 'afebrile', 'hemodynamically', 'normal', 'pulse', '7080s', 'systolic', 'pressure', '120s', 'oxygen', 'saturation', '100', '2', 'l', 'unremarkable', 'physical', 'examination', 'trace', 'edema', 'extremities', 'clean', 'wound', 'patient', 'safely', 'discharged', 'home', 'home', 'physical', 'therapy', 'home', 'oxygenation', 'time', 'discharge', 'hematocrit', '30', 'bun', 'creatinine', '19', '06', 'folast', 'stitle', '996p', 'discharged', 'home', 'followup', 'primary', 'care', 'physician', 'namepattern4', '', 'stitle', '', 'dr', 'prefixes', '', 'weeks', 'discharge', 'medications', 'lopressor', '25', 'mg', 'po', 'bid', 'colace', '100', 'mg', 'po', 'bid', 'needed', 'zantac', '150', 'mg', 'po', 'bid', 'needed', 'aspirin', '81', 'mg', 'po', 'daily', 'ibuprofen', '400', 'mg', 'po', 'q8', 'hours', 'needed', 'dorzolamidetimolol', '205', 'eye', 'drops', '1', 'drop', 'bid', 'pilocarpine', '1', 'drops', '1', 'drop', 'q8', 'hours', 'latanoprost', '0005', 'drops', '1', 'drop', 'bed', 'time', 'metformin', '500', 'mg', 'po', 'daily', 'synthroid', '50', 'mcg', 'po', 'daily', 'lasix', '20', 'mg', 'po', 'bid', '5', 'days', 'potassium', 'chloride', '20', 'meq', 'po', 'bid', '45', 'days', 'disposition', 'patient', 'discharged', 'home', 'home', 'physical', 'therapy', 'home', 'oxygen']\n",
      "453\n"
     ]
    }
   ],
   "source": [
    "m = (dt_table_shuffled[:1].TEXT.values.astype(str))[0]\n",
    "\n",
    "#print (m)\n",
    "idx1 = m.find('ADMISSION DIAGNOSIS')\n",
    "idx2 = m.find('DISCHARGE DIAGNOSIS')\n",
    "idx3 = m.find('[**Doctor Last Name **]')\n",
    "print (idx1, idx2, idx3)\n",
    "print (m[idx1:idx3].strip())\n",
    "l = m[idx1:idx3].strip()\n",
    "l = preprocess(l)\n",
    "print (l)#\n",
    "print (len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only take the last 500 words, instead take the middle useful and preprocess that\n",
    "def get_sentence(data):\n",
    "    X = []\n",
    "    for notes in data:\n",
    "        idx1 = m.find('ADMISSION DIAGNOSIS')\n",
    "        #idx2 = m.find('DISCHARGE DIAGNOSIS')\n",
    "        idx3 = m.find('[**Doctor Last Name **]')\n",
    "        #print (idx1, idx2, idx3)\n",
    "        #print (m[idx1:idx3].strip())\n",
    "        l = m[idx1:idx3].strip()\n",
    "        l = preprocess(l)\n",
    "        #print (l)\n",
    "        #break\n",
    "        X.append(l)\n",
    "    return X\n",
    "X_all = get_sentence(dt_table_shuffled.TEXT.values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.array(X_all)\n",
    "\n",
    "len(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingIdx = {}\n",
    "with open(\"../biomedicalWordVectors/word2vecTools/types.txt\",encoding=\"utf8\") as types, open(\"../biomedicalWordVectors/word2vecTools/vectors.txt\",encoding=\"utf8\") as vectors:    \n",
    "    for word, vector in zip(types, vectors):\n",
    "        word = word.strip()\n",
    "        values = vector.strip().split()\n",
    "        coeffs = np.asarray(values, dtype='float32')\n",
    "        embeddingIdx[word] = coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dt_table_shuffled.LABEL.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "22540833\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "#embeddingMatrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "embeddingMatrix = np.zeros((len(dt_table_shuffled), EMBEDDING_DIM))\n",
    "\n",
    "unknownWord = defaultdict(int)\n",
    "knownwordCount = 0\n",
    "index2word = defaultdict(str)\n",
    "\n",
    "for idx in range(len(X_all)):\n",
    "    text = X_all[idx]\n",
    "    #vec = np.zeros(EMBEDDING_DIM, dtype=float)\n",
    "    for word in text:\n",
    "        vec = np.zeros(EMBEDDING_DIM, dtype=float)\n",
    "        # Get the embedding for word w\n",
    "        if word not in embeddingIdx: # This word has no entry in the embeddings dict of word2vec representation we created\n",
    "            unknownWord[word] += 1\n",
    "            continue \n",
    "        \n",
    "        vec = embeddingIdx[word]\n",
    "        embeddingMatrix[idx] += vec\n",
    "        knownwordCount += 1\n",
    "    # Average the feature vector by the length of the title\n",
    "    if len(text) != 0: embeddingMatrix[idx] = embeddingMatrix[idx]/float(len(text))\n",
    "\n",
    "print(len(unknownWord))\n",
    "print(knownwordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddingMatrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val = train_test_split(embeddingMatrix, train_size=0.75, random_state=0)\n",
    "Y_train, Y_val = train_test_split(label, train_size=0.75, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight dictionary for the +ve and -ve classes\n",
    "weightDict = { 1:8.07217308907, 0:0.53301562141}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 200\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(len(embeddingMatrix),\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 200)          10222600  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                29824     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,252,457\n",
      "Trainable params: 29,857\n",
      "Non-trainable params: 10,222,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bulid LSTM model:\n",
    "hidden_size = 32\n",
    "max_epochs = 10\n",
    "batch_size = 128\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# return the last output from LSTM --> use this as a representation for the entire sequence\n",
    "# the paper : Predicting hospital readmission for lupus patients: An RNN-LSTM-based T deep-learning methodology\n",
    "# used hidden_size = 32, minibatch = 512, Adam, sigmoid for output activation, and binary cross-entropy\n",
    "model.add(LSTM(hidden_size, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam(lr=0.0001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38334, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "38334/38334 [==============================] - 45s 1ms/step - loss: 0.7188 - acc: 0.4077\n",
      "Epoch 2/70\n",
      "38334/38334 [==============================] - 46s 1ms/step - loss: 0.7091 - acc: 0.5052\n",
      "Epoch 3/70\n",
      "38334/38334 [==============================] - 47s 1ms/step - loss: 0.7080 - acc: 0.4965\n",
      "Epoch 4/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.7055 - acc: 0.5181\n",
      "Epoch 5/70\n",
      "38334/38334 [==============================] - 47s 1ms/step - loss: 0.7065 - acc: 0.4995\n",
      "Epoch 6/70\n",
      "38334/38334 [==============================] - 47s 1ms/step - loss: 0.7046 - acc: 0.5094\n",
      "Epoch 7/70\n",
      "38334/38334 [==============================] - 51s 1ms/step - loss: 0.7048 - acc: 0.4993\n",
      "Epoch 8/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.7026 - acc: 0.5202\n",
      "Epoch 9/70\n",
      "38334/38334 [==============================] - 51s 1ms/step - loss: 0.7022 - acc: 0.4908\n",
      "Epoch 10/70\n",
      "38334/38334 [==============================] - 55s 1ms/step - loss: 0.7017 - acc: 0.5013\n",
      "Epoch 11/70\n",
      "38334/38334 [==============================] - 52s 1ms/step - loss: 0.7016 - acc: 0.5089\n",
      "Epoch 12/70\n",
      "38334/38334 [==============================] - 51s 1ms/step - loss: 0.6993 - acc: 0.4974\n",
      "Epoch 13/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.6962 - acc: 0.5117\n",
      "Epoch 14/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.6969 - acc: 0.5185\n",
      "Epoch 15/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6985 - acc: 0.5111\n",
      "Epoch 16/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6977 - acc: 0.5152\n",
      "Epoch 17/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6962 - acc: 0.5222\n",
      "Epoch 18/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6967 - acc: 0.5088\n",
      "Epoch 19/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6949 - acc: 0.5206\n",
      "Epoch 20/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6974 - acc: 0.5096\n",
      "Epoch 21/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6950 - acc: 0.4948\n",
      "Epoch 22/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.6931 - acc: 0.5335\n",
      "Epoch 23/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6942 - acc: 0.5235\n",
      "Epoch 24/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6939 - acc: 0.5157\n",
      "Epoch 25/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.6932 - acc: 0.5167\n",
      "Epoch 26/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6932 - acc: 0.5225\n",
      "Epoch 27/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6901 - acc: 0.5304\n",
      "Epoch 28/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.6921 - acc: 0.5366\n",
      "Epoch 29/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6934 - acc: 0.5300\n",
      "Epoch 30/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6936 - acc: 0.5323\n",
      "Epoch 31/70\n",
      "38334/38334 [==============================] - 51s 1ms/step - loss: 0.6931 - acc: 0.5131\n",
      "Epoch 32/70\n",
      "38334/38334 [==============================] - 52s 1ms/step - loss: 0.6932 - acc: 0.5411\n",
      "Epoch 33/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6909 - acc: 0.5482\n",
      "Epoch 34/70\n",
      "38334/38334 [==============================] - 47s 1ms/step - loss: 0.6917 - acc: 0.5177\n",
      "Epoch 35/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6920 - acc: 0.5392\n",
      "Epoch 36/70\n",
      "38334/38334 [==============================] - 48s 1ms/step - loss: 0.6923 - acc: 0.5191\n",
      "Epoch 37/70\n",
      "38334/38334 [==============================] - 53s 1ms/step - loss: 0.6924 - acc: 0.5245\n",
      "Epoch 38/70\n",
      "38334/38334 [==============================] - 52s 1ms/step - loss: 0.6906 - acc: 0.5229\n",
      "Epoch 39/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6908 - acc: 0.5533\n",
      "Epoch 40/70\n",
      "38334/38334 [==============================] - 52s 1ms/step - loss: 0.6914 - acc: 0.5449\n",
      "Epoch 41/70\n",
      "38334/38334 [==============================] - 75s 2ms/step - loss: 0.6922 - acc: 0.5466\n",
      "Epoch 42/70\n",
      "38334/38334 [==============================] - 104s 3ms/step - loss: 0.6918 - acc: 0.5321\n",
      "Epoch 43/70\n",
      "38334/38334 [==============================] - 103s 3ms/step - loss: 0.6905 - acc: 0.5186\n",
      "Epoch 44/70\n",
      "38334/38334 [==============================] - 102s 3ms/step - loss: 0.6906 - acc: 0.5602\n",
      "Epoch 45/70\n",
      "38334/38334 [==============================] - 104s 3ms/step - loss: 0.6913 - acc: 0.5292\n",
      "Epoch 46/70\n",
      "38334/38334 [==============================] - 103s 3ms/step - loss: 0.6905 - acc: 0.5470\n",
      "Epoch 47/70\n",
      "38334/38334 [==============================] - 102s 3ms/step - loss: 0.6911 - acc: 0.5488\n",
      "Epoch 48/70\n",
      "38334/38334 [==============================] - 97s 3ms/step - loss: 0.6911 - acc: 0.5641\n",
      "Epoch 49/70\n",
      "38334/38334 [==============================] - 57s 1ms/step - loss: 0.6906 - acc: 0.5270\n",
      "Epoch 50/70\n",
      "38334/38334 [==============================] - 61s 2ms/step - loss: 0.6901 - acc: 0.5475\n",
      "Epoch 51/70\n",
      "38334/38334 [==============================] - 65s 2ms/step - loss: 0.6907 - acc: 0.5524\n",
      "Epoch 52/70\n",
      "38334/38334 [==============================] - 62s 2ms/step - loss: 0.6908 - acc: 0.5546\n",
      "Epoch 53/70\n",
      "38334/38334 [==============================] - 60s 2ms/step - loss: 0.6907 - acc: 0.5506\n",
      "Epoch 54/70\n",
      "38334/38334 [==============================] - 63s 2ms/step - loss: 0.6906 - acc: 0.5429\n",
      "Epoch 55/70\n",
      "38334/38334 [==============================] - 65s 2ms/step - loss: 0.6904 - acc: 0.5373\n",
      "Epoch 56/70\n",
      "38334/38334 [==============================] - 62s 2ms/step - loss: 0.6908 - acc: 0.5306\n",
      "Epoch 57/70\n",
      "38334/38334 [==============================] - 64s 2ms/step - loss: 0.6907 - acc: 0.5588\n",
      "Epoch 58/70\n",
      "38334/38334 [==============================] - 64s 2ms/step - loss: 0.6901 - acc: 0.5321\n",
      "Epoch 59/70\n",
      "38334/38334 [==============================] - 60s 2ms/step - loss: 0.6909 - acc: 0.5699\n",
      "Epoch 60/70\n",
      "38334/38334 [==============================] - 65s 2ms/step - loss: 0.6899 - acc: 0.5243\n",
      "Epoch 61/70\n",
      "38334/38334 [==============================] - 64s 2ms/step - loss: 0.6904 - acc: 0.5666\n",
      "Epoch 62/70\n",
      "38334/38334 [==============================] - 57s 1ms/step - loss: 0.6902 - acc: 0.5628\n",
      "Epoch 63/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6904 - acc: 0.5180\n",
      "Epoch 64/70\n",
      "38334/38334 [==============================] - 51s 1ms/step - loss: 0.6900 - acc: 0.5403\n",
      "Epoch 65/70\n",
      "38334/38334 [==============================] - 52s 1ms/step - loss: 0.6897 - acc: 0.5535\n",
      "Epoch 66/70\n",
      "38334/38334 [==============================] - 52s 1ms/step - loss: 0.6901 - acc: 0.5915\n",
      "Epoch 67/70\n",
      "38334/38334 [==============================] - 53s 1ms/step - loss: 0.6896 - acc: 0.5189\n",
      "Epoch 68/70\n",
      "38334/38334 [==============================] - 50s 1ms/step - loss: 0.6896 - acc: 0.5460\n",
      "Epoch 69/70\n",
      "38334/38334 [==============================] - 49s 1ms/step - loss: 0.6898 - acc: 0.5293\n",
      "Epoch 70/70\n",
      "38334/38334 [==============================] - 47s 1ms/step - loss: 0.6904 - acc: 0.5349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3be7462b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the network:\n",
    "model.fit(X_train, Y_train, epochs=max_epochs, batch_size=batch_size, class_weight=weightDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model description and weights\n"
     ]
    }
   ],
   "source": [
    "# Save trained model to JSON:\n",
    "modelJson = model.to_json()\n",
    "with open(\"trainedModel_70_epochs.json\", \"w\") as f:\n",
    "    f.write(modelJson)\n",
    "model.save_weights(\"trainedWeights_70_epochs.h5s\")\n",
    "print(\"Saved model description and weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12779,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "y_valPred = model.predict_classes(X_val)\n",
    "y_valPred = np.reshape(y_valPred, (-1))\n",
    "print(y_valPred.shape)\n",
    "print(y_valPred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training:  0.5\n",
      "AUC for validation:  0.5\n",
      "0\n",
      "821\n",
      "Macro F1 score: 0.000000, Micro F1 score: 0.935754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl0VPXdx/H3l7BvAQFFlggissqSzGRR61I3pFVatQoK2D62PrK5L9S1aq1V61oBpWo1rOJSRR9cqnWrJiGBACGRJawJ+5awBkjm9/yR1JNiIANMcjMzn9c5OWdm7i8znx+TfLi5M/O75pxDREQiSz2vA4iISOip3EVEIpDKXUQkAqncRUQikMpdRCQCqdxFRCKQyl1EJAKp3EVEIpDKXUQkAtX36oHbtm3runTp4tXDi4iEpXnz5m11zrWrbpxn5d6lSxeysrK8engRkbBkZmuCGafDMiIiEUjlLiISgVTuIiIRSOUuIhKBVO4iIhGo2nI3s9fMbLOZLT7MdjOzF8ws38wWmVl86GOKiMjRCGbP/XVg0BG2Xwp0r/i6EZh0/LFEROR4VFvuzrmvge1HGDIESHXl0oFWZnZyqAKKiESKfXt2kfbyGDasWVrjjxWKY+4dgYJK1wsrbvsRM7vRzLLMLGvLli0heGgRkfCw+NsP2P6XBFI2TGVtxvs1/nih+ISqVXFblWfdds5NBiYD+Hw+nZlbRCLezqJtLEm9hcTtH1BoJ5N78QySzhxc448binIvBDpXut4JWB+C+xURCWsL/jmdDt/eR4LbQVqH4Qwc8QSdmjavlccORbnPBsaa2UwgCSh2zm0Iwf2KiISlbZsKWT11LAm7vmBVvS4UX/YGKQPPqdUM1Za7mc0AzgPamlkh8BDQAMA59xIwBxgM5AN7gd/UVFgRkbrMBQLM+3Ay3eb/kTPcPtK63ETCtQ/TsFHjWs9Sbbk754ZVs90BY0KWSEQkDG0syGfT9NH49mWwtH5PGl85kZReCZ7l8WzJXxGRSBAoKyPznWfok/s0LQmQ3uMu/FePJ6a+t/WqchcROUYF+TnsmjWKpAM55DQeSJuhL5HctafXsQCVu4jIUSs9eICsGY8yYMUkYq0Bmf0ewfeLcVi9urNcl8pdROQorMhJJ/DeGJLL8sludhadhk/E36GL17F+ROUuIhKE/SV7mT/1PnwFb7DTmjMv8TniB11fp/bWK1O5i4hUY0nmZzT56FZSAgVktrqE7iNeIKFte69jHZHKXUTkMPbuLmZR6p0kbnqLzdaWRee+iv/8q7yOFRSVu4hIFXK+fp82X9xJsttMRrsr6DPyGdq3bO11rKCp3EVEKinevoWlqTeTWDSHAutA3qA3SUo+0ikt6iaVu4hIhfmfTCEu7X7i3U7SOo5k4Ig/07lJM69jHROVu4hEva0bC1g7dQzxu79iRcypFF0+jZT+Z3sd67io3EUkarlAgKzZkzh9wWP0dftJ7zqGhGsfokHDRl5HO24qdxGJShvXLmfz9FH4SzJZ0qA3Ta6aRHKPAV7HChmVu4hElUBZGZlvP0XfvGdpiSOj13j8v7qbejExXkcLKZW7iESNtcsWsOet0SQdzGVRkwTaDp1EUpceXseqESp3EYl4Bw/sJ2vGI8SvfJkSa0jmgMfwXT66zi4dEAoqdxGJaPkLv4XZ40gpW8H85ucQN2IC/vZxXseqcSp3EYlIJfv2kD31XvyFqRRZS+YnP0/8oF97HavWqNxFJOIsyfiUpp/cSkpgHXNbD6bHiOeIb3OS17FqlcpdRCLG7p07yE29A/+Wd9lkbck5/+8knnuF17E8oXIXkYiw6Mt3OPHLe/C7rcw98SrOGPkXTm7RyutYnlG5i0hYK962iWWpN+Mv/pg19Tqx7JJZJCdd7HUsz6ncRSRszf/4deLSH2Kg20lap98wcPhjNA7Thb5CTeUuImFn6/o1rJ02hvg935Af043iITNI6Xem17HqFJW7iIQNFwiQ+f4Eei58nD7uAGndbsY/7AHqN2jodbQ6R+UuImFh/eqlbJtxE4n755PXoC8trp5ISvf+Xseqs1TuIlKnlZWWkvnWE/Rb8jyxGBm978V/1Z0Rt9BXqKncRaTOWrNkPvveGUPywTwWNfFz4rWTSIrr7nWssKByF5E65+CB/WRNf4iEVX9jrzUmc+Dj+C67KaIX+go1lbuI1CnLF3xDvQ/GkVK2inktzuOU4S/ib9/Z61hhJ6j/Bs1skJktNbN8MxtfxfY4M/vCzLLNbJGZDQ59VBGJZCV7d5P28ji6/uNyWpYVkX3mBBLufJ+2KvZjUu2eu5nFABOAi4BCINPMZjvn8ioNux+Y5ZybZGa9gTlAlxrIKyIRKC/tI1p8ejspbj1zT/gZPUa+wMDWbb2OFdaCOSyTCOQ751YCmNlMYAhQudwd0LLiciywPpQhRSQy7SreTt6UO0ja+i7r7SQWX5BK4k+GeB0rIgRT7h2BgkrXC4GkQ8b8AfjUzMYBzYALQ5JORCLWwi/e4qSvxuN320g/6Rr6jXyKDs1jvY4VMYIpd6viNnfI9WHA6865p80sBZhiZn2dc4H/uiOzG4EbAeLiIv9MKCLyY0VbN7J8yjj8xZ+yul5nlg1+h2TfBV7HijjBvKBaCFR+RaMTPz7scgMwC8A5lwY0Bn50wMw5N9k553PO+dq1a3dsiUUkLLlAgHlzXiXwop8BRZ+T1vm3nHz3XHqq2GtEMHvumUB3M+sKrAOGAtceMmYtcAHwupn1orzct4QyqIiEry3rV1M4dRQJe79jef3uFP1iAil9Dz26K6FUbbk750rNbCzwCRADvOacyzWzR4As59xs4A7gb2Z2G+WHbH7tnDv00I2IRBkXCJD5jxfomfMEvdxB0rvfiu+a+7TQVy0I6kNMzrk5lL+9sfJtD1a6nAecFdpoIhLO1q38nh1v3kTi/gXkNjyD2KtfIvm0vl7Hihr6hKqIhFRZaSmZsx6n39K/Eks9Mvo+gP+K27TQVy1TuYtIyKz+Pov974wmuXQpC5sm0f66SSR16uZ1rKikcheR43Zgfwnzpj1IwppX2GNNyUp4koSf/U4LfXlI5S4ix2XZ/K9o8OHNpARWk9XyAk4d8Vd8J3b0OlbUU7mLyDHZt2cXC6fcg3/DdLZZaxac/RK+C4d5HUsqqNxF5Kjlfvt/xH52B8luAxltLqfXyOcY0KqN17GkEpW7iARtZ9E2vp9yG0nb3qfQ2rP4oqkknXWZ17GkCip3EQnKgs9n0uGb3+NzO0hvP4z+I5+iU7MWXseSw1C5i8gRbd+8jpVTxuHb9Tmr6p1C0c//TnL8eV7Hkmqo3EWkSuULfb1Ct6xH6ef2kHbK/5Jw3SM0bNTY62gSBJW7iPzIpsIVbJg2Gt++dJbVP52iKyaS0tvvdSw5Cip3EflBoKyMzHefo/fip+hBGemn34H/mnuJqa+qCDd6xkQEgML8xRTPGkXSgUXkNupPq6GTSD61j9ex5Bip3EWiXOnBA2S9+Sf6L59ALDHM7fcH/L+8RUsHhDmVu0gUW5WbwcF/jCW5dBnZzc6k43UTSezY1etYEgIqd5EotL9kL/OnPYBv7d/ZZc2Y53+a+Ev/R3vrEUTlLhJllmb9i0ZzbiElsJas2IvoNuKvJLQ72etYEmIqd5EosXd3MYum3E3ixjfZYiew8JyX8f10qNexpIao3EWiwOJ/z6b153eS7DaR0fYX9B75LP1jT/A6ltQglbtIBCvesZWlqbeQuONDCqwDuRfPIOnMwV7HklqgcheJUNmfTqXTd/eT4IpI6zCcgSOeoHPT5l7HklqicheJMNs2FbJ66lgSdn3BynpdKLoslZSB53gdS2qZyl0kQrhAgHkfvsxp8//IGa6EtC434bvuERo0bOR1NPGAyl0kAmwsyGfT9FH49s1laf2eNL5yIim9EryOJR5SuYuEsUBZGZnvPE2f3GdoSYD0Hnfhv3q8FvoSlbtIuCpYvpBds0aTdHAxOY0H0mboSyR37el1LKkjVO4iYab04AGyZjzKgBWTiLWGzO3/KP4hY7V0gPwXlbtIGFmRk457bzTJZSvIbn42na+bSGKHU7yOJXWQyl0kDOwv2cv8qffhK3iDndac+UnPMfCS67W3Loelchep45bM/SdNPr6NlEABma0uofuIF4hv297rWFLHqdxF6qg9u4rISb2TxM1vs9nasujcV/Gff5XXsSRMBPU3nZkNMrOlZpZvZuMPM+ZqM8szs1wzmx7amCLRJefrf1D8jJ/kLW+R2e4Kmt+eST8VuxyFavfczSwGmABcBBQCmWY22zmXV2lMd+D3wFnOuR1mdmJNBRaJZMXbt7A09WYSi+awtl5Hvh80i6SkS7yOJWEomMMyiUC+c24lgJnNBIYAeZXG/A6Y4JzbAeCc2xzqoCKRbv4nU4hLu594t5O0jtczcMTjNG7SzOtYEqaCKfeOQEGl64VA0iFjTgcws2+BGOAPzrmPD70jM7sRuBEgLi7uWPKKRJytG9eyduoY4nd/zYqYUym6fBop/c/2OpaEuWDK3aq4zVVxP92B84BOwDdm1tc5V/Rf3+TcZGAygM/nO/Q+RKKKCwTImj2R0xf8iT7uAGmnjsE37CEt9CUhEUy5FwKdK13vBKyvYky6c+4gsMrMllJe9pkhSSkSYTasWcqWGaPxl2TxfYPeNL1qEik9BngdSyJIMO+WyQS6m1lXM2sIDAVmHzLmPeB8ADNrS/lhmpWhDCoSCQJlZWTMfJzY137CaftyyOg5nh7j/80pKnYJsWr33J1zpWY2FviE8uPprznncs3sESDLOTe7YtvFZpYHlAF3Oee21WRwkXCzdtkC9rw1iqSDeSxq4qPdsIkkndLD61gSocw5bw59+3w+l5WV5clji9Smgwf2kzXjYeJXTqbEGrJswL34Lh+tpQPkmJjZPOecr7px+oSqSA3KX/gtNnssKWUrmd/iHOKGT8DfXu8Uk5qnchepASX79pA9ZTz+dVMpspZkp7xA/CXXex1LoojKXSTEvs/4hOYf30qKW8/c1oPpMfIFBp7QzutYEmVU7iIhsnvnDnJTbydp67ustxPJ+enrJJ7zS69jSZRSuYuEwKIv3+HEL+/B77aSfuKvOGPkX+jQopXXsSSKqdxFjkPxtk0sSx2Hv/gT1tTrxLJBb5GceJHXsURU7iLHwgUCZH/yBqdkPMQAt5u0Tr9h4PDHtNCX1Bkqd5GjtHX9GgqmjSZ+z7/Jj+lG0ZCZpPQ70+tYIv9F5S4SJBcIkPn+i/Rc+Gd6uQOkd7sZ37AHqN+godfRRH5E5S4ShPWrlrBt5k0k7s8mr0FfWlw9keTu/b2OJXJYKneRIygrLSXzrSfot+R5YjEy+tyH/8o7qBcT43U0kSNSuYscxpol89n39miSS79nYRM/J107iaS47l7HEgmKyl3kEAcP7Cdr2oMkrH6FvdaYrPg/k/Dz/9VCXxJWVO4ilSxf8A0xs8eSEljNvJbn02X4i/hO6uR1LJGjpnIXAUr27iZ7yj0krp/GdmtF9pkTSLh4uNexRI6Zyl2iXl7aR7T49Pbyhb5O+Dk9Rj7PwNZtvY4lclxU7hK1dhVvJy/1NpK2vcd6O4nFF6SS+JMhXscSCQmVu0Slhf+aRfuvx+N320lvP5R+I56kQ/NYr2OJhIzKXaLKji0bWDFlLL6dn7G6XmeWDf4byb4LvI4lEnIqd4kKLhBg/kev0TXzYfq7PaTF/Zb46x6lUeOmXkcTqREqd4l4W9avpnDqKBL2fsfy+t0p/uUEUvokeR1LpEap3CViuUCAzH88T8+cJ+nlDpLe/TZ819yrhb4kKqjcJSKtW/k9O968icT9C8hteAaxV79E8ml9vY4lUmtU7hJRykpLyXzzT/Rf9ldiiSGj74P4r7hVC31J1FG5S8RYlZfJwXdHk1y6jIVNk2h/3SSSOnXzOpaIJ1TuEvYO7C9h3rQHSFjzKnusGVm+p0gY/Fst9CVRTeUuYW3Z/K9o8OE4UgJryIq9kFOHv4DvxI5exxLxnMpdwtK+PbtYmHoX/o0z2WatWXD2S/guHOZ1LJE6Q+UuYWfxtx/Q6rM7SXYbyWg7hF4jnmVAqzZexxKpU1TuEjZ2Fm3j+9RbSdo+m0Jrz+KLppJ01mVexxKpk4J6xcnMBpnZUjPLN7PxRxh3lZk5M/OFLqIILPhsBiXP+fBt+4D09tfR5s4s+qrYRQ6r2j13M4sBJgAXAYVAppnNds7lHTKuBXAzkFETQSU6bd+8jpVTxuHb9Tmr6nWh6Oevkxx/rtexROq8YPbcE4F859xK59wBYCZQ1aLXjwJPAiUhzCdRygUCZH3wMjYxiX47vyQt7n/peE8Gp6vYRYISzDH3jkBBpeuFwH+tumRmA4HOzrkPzezOEOaTKLSpcAUbpo3Gty+dpfV70OjKiaT00pE+kaMRTLlbFbe5Hzaa1QOeBX5d7R2Z3QjcCBAXFxdcQokagbIyMt99lj6L/0IPykg//Q7819xLTH297i9ytIL5rSkEOle63glYX+l6C6Av8KWZAbQHZpvZ5c65rMp35JybDEwG8Pl8DpEKBfk57Jw1iqQDOSxuPIDW17xE8qm9vI4lEraCKfdMoLuZdQXWAUOBa/+z0TlXDPxwNmEz+xK489BiF6lK6cEDZL35GAOWTyDWGjD3jIfx//JmLR0gcpyqLXfnXKmZjQU+AWKA15xzuWb2CJDlnJtd0yElMq1cnEHZe2NILl1OdrMz6TR8EokdungdSyQiBHUw0zk3B5hzyG0PHmbseccfSyLZ/pK9zJ/2AL61f2eXNWNe4jPED/qN9tZFQkivVEmtWpL1OY3n3EJKoICs2Is4beSLJLRt73UskYijcpdasXd3MYtS7yJx0yy22AksPOdv+H56tdexRCKWyl1q3OJv3ueEf91FsttERttf0Hvks/SPPcHrWCIRTeUuNaZ4x1aWpt5M4o7/o8A6kHfJTJJSLvU6lkhUULlLjcj+dCqdvrufeFdMWoeRDBzxOJ2bNvc6lkjUULlLSG3dWMCaqWNJ2P0lK2K6UnTZFFIG/MTrWCJRR+UuIVG+0NdLdM9+jDNcCWldR+G79mEaNGzkdTSRqKRyl+O2ce1yNk0fhb8kkyX1e9Hkqomk9Iz3OpZIVFO5yzELlJWR+fZf6Jv3DC1xpPe8G/+v7tFCXyJ1gH4L5ZgULF/IrlmjSTq4mJzG8bQZOonkrj29jiUiFVTuclRKDx4gc8ajxK+YRKw1ZG7/P+IfMkZLB4jUMSp3CdqKnHTce6NJKVtBdvOz6XzdRBI7nOJ1LBGpgspdqlWybw/ZU+/DV5hKsbVgfvLzxA/6tdexROQIVO5yREvm/pMmH99KSqCQzFaDOH3kC8S3OcnrWCJSDZW7VGnPriIWp96Bf/M7bLa2LDrvNfznXel1LBEJkspdfiTnq3dp+8Xd+N1WMttdQZ+RT9O+ZWuvY4nIUVC5yw+Kt29hWeo4/EUfsbZeR5Ze8iZJSZd4HUtEjoHKXQDI/uQNOqc9yEC3k7SO1zNwxOM0btLM61gicoxU7lFu68a1rJ0yhvg9X7Mi5lSKLp9OSv+zvI4lIsdJ5R6lXCBA5vsT6LHwcfq4A6SdOgbfsIe00JdIhFC5R6H1q5eydeYoEkvm8X2D3jS9ahIpPQZ4HUtEQkjlHkUCZWXMnfUE/ZY8RyxGRu/f47/qLurFxHgdTURCTOUeJdYsXcDet0eRfDCPRU18tBs2kaRTengdS0RqiMo9wh08sJ950x8mftXL7LNGZA74E77LR2mhL5EIp3KPYPkL/43NHkdy2UrmtziHuOET8bfv7HUsEakFKvcIVLJ3N9lTf49/3VSKrCXZKS8Qf8n1XscSkVqkco8w32d8QvOPbyXFrWdu68H0GPkCA09o53UsEallKvcIsXvnDnJTbydp67ustxPJ+WkqiecM8TqWiHhE5R4BFn7xFid9NR6/20b6SVdzxoin6NCildexRMRDKvcwVrR1I8unjMNf/Clr6nVm2aVvk+y/0OtYIlIHqNzDkAsEmP/xG3SZ+xAD3G7SOv8P8cMfo1Hjpl5HE5E6IqhyN7NBwPNADPCKc+7Ph2y/HfgtUApsAf7HObcmxFkF2Lp+DQVTR5Gw91uWx5xG0S9mkXJGstexRKSOqfaTLGYWA0wALgV6A8PMrPchw7IBn3OuH/A28GSog0Y7FwiQ+e7zNJycTK89c0nvdgtdx6fRTcUuIlUIZs89Ech3zq0EMLOZwBAg7z8DnHNfVBqfDgwPZchot37VErbNvAn//mzyGp5Bi19NILl7f69jiUgdFky5dwQKKl0vBJKOMP4G4KOqNpjZjcCNAHFxcUFGjF5lpaVkzvoz/Za+QEvqkdHnfvxX3q6FvkSkWsGUu1Vxm6tyoNlwwAecW9V259xkYDKAz+er8j6k3Jrv51HyzmiSS5ewsImfk657iaTOp3kdS0TCRDDlXghUXpCkE7D+0EFmdiFwH3Cuc25/aOJFnwP7S5g3/SESVr/CHmtCVvwTJPz8Ri30JSJHJZhyzwS6m1lXYB0wFLi28gAzGwi8DAxyzm0OecoosTz7a2I+GEdKYDXzWv6ULsP/iu+kTl7HEpEwVG25O+dKzWws8Anlb4V8zTmXa2aPAFnOudnAU0Bz4C0zA1jrnLu8BnNHlJK9u1mQejf+DdPZZq1ZcNYkEi66tvpvFBE5jKDe5+6cmwPMOeS2Bytd1scij1Hud3OI/eftJLsNzG1zGT1GPMeA1m29jiUiYU6fUPXIruLt5KXeRtK291hnJ7H4wikknq0/dkQkNFTuHlj4r5m0//pefG476e2H0W/EE3RsHut1LBGJICr3WrRjywZWTBmLb+dnrK7XmfzBr5Ds+6nXsUQkAqnca4ELBJj30at0y3yEfm4PaXG/I/66R7TQl4jUGJV7Ddu8bhXrpo3Gt/c7ltU/naJfvkhKnyN9wFdE5Pip3GtI+UJfz9Er50l6UkZ699vwD72fmPr6JxeRmqemqQHrVuZSNHMUiQcWktuoH7FXTyL5tL5exxKRKKJyD6Gy0lIy33yM/stepCUxZPR9EP8Vt2qhLxGpdSr3EFmVl8nBd0eTXLqMBU2TOfm6iSR16uZ1LBGJUir343Rgfwnzpj1AwppX2WPNyPL/hYRLb9BCXyLiKZX7cVg2/0safHgzKYE1ZMVeSLcRL+Jrd7LXsUREVO7HYt+eXSxMvQv/xpnlC3395GV8Fwz1OpaIyA9U7kdp8bcf0PqzO0h2m8hoO4ReI55lQKs2XscSEfkvKvcg7SzaxpLUW0jc/gGF1p7ci6aTdNbPvI4lIlIllXsQFnw2gw7/vpcEt4P0k6+j/4gn6NSshdexREQOS+V+BNs3r2PVlLEk7PoXq+p1oejnr5McX+XpYUVE6hSVexVcIMC8DyfTbf4fOcPtJa3LTSRc+zANGzX2OpqISFBU7ofYWJDPpumj8e3LYGn9HjS6ciIpvXxexxIROSoq9wqBsjIy33mGPrlP05IA6T3uxH/177XQl4iEJTUXUJCfw85Zo0g6kMPixgNofc1LJJ/ay+tYIiLHLKrLvfTgAbJm/pEB+ROJtQbMPeNh/L+8WUsHiEjYi9pyX7k4g7L3xpBcupzsZmfSafgkEjt08TqWiEhIRF257y/ZS/bU+0koeJ2d1px5ic8RP+h67a2LSESJqnJfkvkZTT66leRAAZmtLqb7iL+S0La917FEREIuKsp97+5iFqXeSeKmt9hsbVh47iv4z/+V17FERGpMxJd7ztfv0+aLO0l2m8lodwW9RzxN/9gTvI4lIlKjIrbci3dsZekb40gsmkOBdSDvkpkkpVzqdSwRkVoRkeWe/elUOn13P/GumLSOIxk4/HE6N23udSwRkVoTUeW+dWMBa6eOIX73V6yI6UrRZVNIGfATr2OJiNS6iCh3FwiQNXsSpy94jL5uP+ldx5Bw7UM0aNjI62giIp4IqtzNbBDwPBADvOKc+/Mh2xsBqUACsA24xjm3OrRRq7Zx7XI2Tx+FvySTJfV70eSqiST3jK+NhxYRqbOqLXcziwEmABcBhUCmmc12zuVVGnYDsMM5d5qZDQWeAK6picD/ESgrI/Ptp+ib9ywtcaT3vAf/r+7WQl8iIgS3554I5DvnVgKY2UxgCFC53IcAf6i4/DbwopmZc86FMOsP1i5bwJ63RpN0MJecxvG0GfYSyV161MRDiYiEpWDKvSNQUOl6IZB0uDHOuVIzKwbaAFtDEbKyzHefp9/CR9lvDZnb/4/4h4zR0gEiIocIptytitsO3SMPZgxmdiNwI0BcXFwQD/1jzTv2JHdFCnEjJpDY/tjuQ0Qk0gVT7oVA50rXOwHrDzOm0MzqA7HA9kPvyDk3GZgM4PP5jumQTa+kSyDpkmP5VhGRqBHM8YxMoLuZdTWzhsBQYPYhY2YD11dcvgr4V00dbxcRkepVu+decQx9LPAJ5W+FfM05l2tmjwBZzrnZwKvAFDPLp3yPfWhNhhYRkSML6n2Dzrk5wJxDbnuw0uUSQMssiojUEXqbiYhIBFK5i4hEIJW7iEgEUrmLiEQglbuISAQyr96ObmZbgDXH+O1tqYGlDeo4zTk6aM7R4XjmfIpzrl11gzwr9+NhZlnOOZ/XOWqT5hwdNOfoUBtz1mEZEZEIpHIXEYlA4Vruk70O4AHNOTpoztGhxucclsfcRUTkyMJ1z11ERI6gTpe7mQ0ys6Vmlm9m46vY3sjM3qzYnmFmXWo/ZWgFMefbzSzPzBaZ2edmdooXOUOpujlXGneVmTkzC/t3VgQzZzO7uuK5zjWz6bWdMdSC+NmOM7MvzCy74ud7sBc5Q8XMXjOzzWa2+DDbzcxeqPj3WGRm8SEN4Jyrk1+ULy+8AjgVaAgsBHofMmY08FLF5aHAm17nroU5nw80rbg8KhrmXDGuBfA1kA74vM5dC89zdyAbaF1x/USvc9fCnCcDoyou9wZWe537OOd8DhAPLD7M9sHAR5SfyS4ZyAjl49flPfcfTsztnDsA/OfE3JUNAd6ouPw2cIGZVXXKv3BR7Zydc1845/ZWXE2n/MxY4SyY5xngUeBJoKQ2w9WQYOb8O2CCc24HgHNucy3NW9diAAACOElEQVRnDLVg5uyAlhWXY/nxGd/CinPua6o4I10lQ4BUVy4daGVmJ4fq8etyuVd1Yu6OhxvjnCsF/nNi7nAVzJwru4Hy//nDWbVzNrOBQGfn3Ie1GawGBfM8nw6cbmbfmlm6mQ2qtXQ1I5g5/wEYbmaFlJ8/YlztRPPM0f6+H5WgTtbhkZCdmDuMBD0fMxsO+IBzazRRzTvinM2sHvAs8OvaClQLgnme61N+aOY8yv86+8bM+jrnimo4W00JZs7DgNedc0+bWQrlZ3fr65wL1Hw8T9Rof9XlPfejOTE3RzoxdxgJZs6Y2YXAfcDlzrn9tZStplQ35xZAX+BLM1tN+bHJ2WH+omqwP9vvO+cOOudWAUspL/twFcycbwBmATjn0oDGlK/BEqmC+n0/VnW53KPxxNzVzrniEMXLlBd7uB+HhWrm7Jwrds61dc51cc51ofx1hsudc1nexA2JYH6236P8xXPMrC3lh2lW1mrK0ApmzmuBCwDMrBfl5b6lVlPWrtnAyIp3zSQDxc65DSG7d69fUa7m1ebBwDLKX2W/r+K2Ryj/5YbyJ/8tIB+YC5zqdeZamPNnwCZgQcXXbK8z1/ScDxn7JWH+bpkgn2cDngHygBxgqNeZa2HOvYFvKX8nzQLgYq8zH+d8ZwAbgIOU76XfANwE3FTpOZ5Q8e+RE+qfa31CVUQkAtXlwzIiInKMVO4iIhFI5S4iEoFU7iIiEUjlLiISgVTuIiIRSOUuIhKBVO4iIhHo/wGhxUiXUYT5mQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation based on AUC and F1 scores and Plot ROC\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "y_trainPred = model.predict_classes(X_train)\n",
    "y_trainPred = np.reshape(y_trainPred, (-1))\n",
    "fpr_train, tpr_train, threshold_train = roc_curve(Y_train, y_trainPred)\n",
    "fpr_val, tpr_val, threshold_val = roc_curve(Y_val, y_valPred)\n",
    "\n",
    "\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "roc_auc_val = auc(fpr_val, tpr_val)\n",
    "\n",
    "\n",
    "plt.plot(fpr_train, tpr_train, label='ROC Curve for training: (%0.2f)' % (roc_auc_train))\n",
    "plt.plot(fpr_val, tpr_val, label='ROC Curve for training: (%0.2f)' % (roc_auc_val))\n",
    "#plt.plot(fpr_test, tpr_test, label='ROC Curve for training: (%0.2f)' % (roc_auc_test))\n",
    "\n",
    "print(\"AUC for training: \", roc_auc_train)\n",
    "print(\"AUC for validation: \", roc_auc_val)\n",
    "ones_count = 0\n",
    "for i in y_valPred:\n",
    "    if i == 1:\n",
    "        ones_count = ones_count + 1\n",
    "print(ones_count)\n",
    "ones_true_count = 0\n",
    "for i in Y_val:\n",
    "    if i == 1:\n",
    "        ones_true_count = ones_true_count + 1\n",
    "print(ones_true_count)\n",
    "macroF1 = f1_score(Y_val, y_valPred)\n",
    "microF1 = f1_score(Y_val, y_valPred, average='micro')\n",
    "\n",
    "print(\"Macro F1 score: %02f, Micro F1 score: %02f\" % (macroF1, microF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38334"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_trainPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11280287],\n",
       "       [0.11280287],\n",
       "       [0.11280287],\n",
       "       ...,\n",
       "       [0.11280287],\n",
       "       [0.11280287],\n",
       "       [0.11280287]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47947,  3166], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51113, 368)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c8d357f229b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(x_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_all.shape)\n",
    "#print(data.shape)\n",
    "#print(text.shape)\n",
    "#print(x_train.shape)\n",
    "#print(y_train.shape)\n",
    "#print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words:\n",
    "#text = dt_table_shuffled.TEXT.values.astype(str)\n",
    "label = dt_table_shuffled.LABEL.values\n",
    "tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(text)\n",
    "tokenizer.fit_on_texts(X_all)\n",
    "#sequences = tokenizer.texts_to_sequences(text)\n",
    "sequences = tokenizer.texts_to_sequences(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51113, 14)\n",
      "51113\n"
     ]
    }
   ],
   "source": [
    "print(dt_table_shuffled.shape)\n",
    "print(dt_table_shuffled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tokenized data into 80% training, 10% validation, and 10% testing\n",
    "indices = np.arange(len(dt_table_shuffled))\n",
    "#np.random.shuffle(indices)\n",
    "#data = \n",
    "n_rows = int(dt_table_shuffled.shape[0])\n",
    "# testing code and model on a quarter of the data\n",
    "data = data[:int(0.25 * n_rows), :]\n",
    "label = label[:int(0.25 * n_rows)]\n",
    "x_train = data[:int(0.8 * n_rows), :]\n",
    "x_val = data[int(0.8 * n_rows):int(0.9 * n_rows), :]\n",
    "x_test = data[int(0.9 * n_rows):, :]\n",
    "y_train = label[:int(0.8 * n_rows)]\n",
    "y_val = label[int(0.8 * n_rows):int(0.9 * n_rows)]\n",
    "y_test = label[int(0.9 * n_rows):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "stemmer = PorterStemmer()\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        #if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "        result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = preprocess(dt_table_shuffled.TEXT.values[0])\n",
    "#print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the BioASQ vocabulary:  1701632\n"
     ]
    }
   ],
   "source": [
    "# prepare the embedding\n",
    "embeddingIdx = {}\n",
    "with open(\"../embeddings/word2vecTools/types.txt\") as types, open(\"../embeddings/word2vecTools/vectors.txt\") as vectors:\n",
    "    for word, vector in zip(types, vectors):\n",
    "        values = vector.split()\n",
    "        coeffs = np.asarray(values, dtype='float32')\n",
    "        embeddingIdx[word] = coeffs\n",
    "print(\"Size of the BioASQ vocabulary: \", len(embeddingIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113994\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "embeddingMatrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "unknownWord = defaultdict(int)\n",
    "knownwordCount = 0\n",
    "index2word = defaultdict(str)\n",
    "for word, i in word_index.items():\n",
    "    embeddingVector = embeddingIdx.get(word)\n",
    "    index2word[i] = word\n",
    "    if embeddingVector is not None:\n",
    "        embeddingMatrix[i] = embeddingVector\n",
    "        knownwordCount = knownwordCount + 1\n",
    "    else:\n",
    "        unknownWord[word] = unknownWord[word] + 1\n",
    "        #embeddingMatrix[i] = np.random.uniform(-0.25, 0.25, 300)\n",
    "        \n",
    "print(len(unknownWord))\n",
    "print(knownwordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21120\n"
     ]
    }
   ],
   "source": [
    "print(index2word[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "#embeddingSentenceMatrix = np.zeros((X_all.shape[0] + 1, EMBEDDING_DIM))\n",
    "embeddingSentenceMatrix = []\n",
    "unknownWord = defaultdict(int)\n",
    "knownwordCount = 0\n",
    "for sentence in data:\n",
    "    sentenceVec = np.zeros(300)\n",
    "    for i in range(len(sentence)):\n",
    "        #word = index2word[i]\n",
    "        sentenceVec = sentenceVec + embeddingMatrix[i]\n",
    "    sentenceVec = sentenceVec / 500\n",
    "    embeddingSentenceMatrix.append(sentenceVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113994\n",
      "(51113, 300)\n"
     ]
    }
   ],
   "source": [
    "print(len(word_index))\n",
    "print(embeddingSentenceMatrix.shape)\n",
    "embeddingSentenceMatrix = np.array(embeddingSentenceMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embeddingMatrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          34198500  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 34,241,157\n",
      "Trainable params: 42,657\n",
      "Non-trainable params: 34,198,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bulid LSTM model:\n",
    "hidden_size = 32\n",
    "max_epochs = 10\n",
    "batch_size = 128\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# return the last output from LSTM --> use this as a representation for the entire sequence\n",
    "# the paper : Predicting hospital readmission for lupus patients: An RNN-LSTM-based T deep-learning methodology\n",
    "# used hidden_size = 32, minibatch = 512, Adam, sigmoid for output activation, and binary cross-entropy\n",
    "model.add(LSTM(hidden_size, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam(lr=0.0001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12778, 500)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51113/51113 [==============================] - 417s 8ms/step - loss: 14.9549 - acc: 0.0619\n",
      "Epoch 2/10\n",
      " 4096/51113 [=>............................] - ETA: 6:11 - loss: 15.0044 - acc: 0.0588"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-55cc0aa901cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training the network:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the network:\n",
    "model.fit(data, label, epochs=max_epochs, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
